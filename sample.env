# MCP Server Environment Variables

# Server configuration
PORT=3000
HOST=localhost
NODE_ENV=development

# Logging configuration
LOG_LEVEL=info # error, warn, info, debug

# Security settings
CORS_ENABLED=true
CORS_ORIGINS=*
RATE_LIMIT_ENABLED=true
RATE_LIMIT_MAX=100
RATE_LIMIT_WINDOW_MS=900000 # 15 minutes

# Module settings
MODULES_AUTOLOAD=true

# ===== MODEL API KEYS AND CONFIGURATION =====

# OpenAI API (for GPT-4)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_ORG_ID=your_openai_org_id_here # Optional
OPENAI_API_BASE_URL=https://api.openai.com/v1
OPENAI_API_VERSION=2023-05-15 # Update to latest version as needed
OPENAI_MAX_TOKENS=4096
OPENAI_TEMPERATURE=0.7
OPENAI_DEFAULT_MODEL=gpt-4 # Can be gpt-4, gpt-4-turbo, gpt-3.5-turbo, etc.

# Stability AI API (for Stable Diffusion)
STABILITY_API_KEY=your_stability_api_key_here
STABILITY_API_BASE_URL=https://api.stability.ai/v1
STABILITY_DEFAULT_ENGINE=stable-diffusion-xl-1024-v1-0 # Update as needed
STABILITY_DEFAULT_STEPS=30
STABILITY_DEFAULT_CFG_SCALE=7
STABILITY_DEFAULT_WIDTH=1024
STABILITY_DEFAULT_HEIGHT=1024

# OpenAI Whisper API (for speech-to-text)
# Note: This uses the same OPENAI_API_KEY as above
WHISPER_DEFAULT_MODEL=whisper-1
WHISPER_DEFAULT_LANGUAGE=en # Optional, auto-detects if not specified
WHISPER_DEFAULT_TEMPERATURE=0
WHISPER_DEFAULT_RESPONSE_FORMAT=json # Can be json, text, srt, verbose_json, or vtt

# Anthropic API (for Claude models, optional)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_API_BASE_URL=https://api.anthropic.com
ANTHROPIC_API_VERSION=2023-06-01 # Update to latest version as needed
ANTHROPIC_DEFAULT_MODEL=claude-3-opus-20240229 # Can be claude-3-opus, claude-3-sonnet, etc.
ANTHROPIC_MAX_TOKENS=4096
ANTHROPIC_TEMPERATURE=0.7

# Hugging Face API (optional)
HUGGINGFACE_API_KEY=your_huggingface_api_key_here
HUGGINGFACE_API_BASE_URL=https://api-inference.huggingface.co/models

# ===== MODEL PROXY SETTINGS =====

# Proxy settings (if needed)
USE_PROXY=false
HTTP_PROXY=http://your-proxy-server:port
HTTPS_PROXY=https://your-proxy-server:port
NO_PROXY=localhost,127.0.0.1

# ===== CACHE SETTINGS =====

# Redis cache settings (optional, for response caching)
REDIS_ENABLED=false
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=your_redis_password_here
REDIS_TTL=3600 # Cache TTL in seconds

# ===== MONITORING AND TELEMETRY =====

# Monitoring settings (optional)
ENABLE_METRICS=true
METRICS_PORT=9090

# ===== ADVANCED SETTINGS =====

# Timeout settings
REQUEST_TIMEOUT_MS=60000 # 60 seconds
INFERENCE_TIMEOUT_MS=120000 # 120 seconds

# Concurrency settings
MAX_CONCURRENT_REQUESTS=10

# Retry settings
MAX_RETRIES=3
RETRY_DELAY_MS=1000